{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688f109b-082d-4540-ab38-6fb50b3ece7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from loguru import logger\n",
    "from datetime import datetime\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0be85a7-e31d-42f9-8bd2-08bd30a61a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineeringProcessor:\n",
    "    def __init__(self, raw_data: pd.DataFrame, pipeline_name: str) -> None:\n",
    "        # Guarda el DataFrame original.\n",
    "        self.raw_data = raw_data\n",
    "        # Guarda el nombre del pipeline.\n",
    "        self.pipeline_name = pipeline_name\n",
    "        # Inicializa la tabla de características como None.\n",
    "        self.feature_table = None\n",
    "\n",
    "    def impute_scale(self, n_components: int = 2) -> pd.DataFrame:\n",
    "        # Define las columnas numéricas a procesar.\n",
    "        numeric_cols= [\n",
    "            \"lead_time\",\n",
    "            \"adults\",\n",
    "            \"children\",\n",
    "            \"babies\",\n",
    "            \"adr\"\n",
    "        ]\n",
    "        pipe = Pipeline(\n",
    "            steps=[\n",
    "                # Imputa valores faltantes con la media.\n",
    "                (\"imputer_mean\", SimpleImputer(strategy=\"mean\")),\n",
    "                # Escala las variables numéricas.\n",
    "                (\"std_scaling\", StandardScaler()),\n",
    "                # Reduce la dimensionalidad con PCA.\n",
    "                (\"pca\", PCA(n_components=n_components))\n",
    "            ]\n",
    "        )\n",
    "        # Devuelve un DataFrame con las nuevas características numéricas.\n",
    "        return pd.DataFrame(\n",
    "            pipe.fit_transform(self.raw_data[numeric_cols]),\n",
    "            columns=[\"great_feature1\", \"great_feature2\"]\n",
    "        )\n",
    "\n",
    "    def encode_categoricals(self) -> pd.DataFrame:\n",
    "        encoded_vars = []\n",
    "        for var in [\"hotel\", \"market_segment\", \"reserved_room_type\"]:\n",
    "            # Muestra en el log qué variable se está codificando.\n",
    "            logger.info(f\"Codificando con OHE {var}\")\n",
    "            encoder = OneHotEncoder()\n",
    "            # Codifica la variable categórica usando OneHotEncoder.\n",
    "            encoded = encoder.fit_transform(self.raw_data[[var]]).toarray()\n",
    "            cols  = [f\"{var}_{col}\" for col in encoder.categories_[0]]\n",
    "            # Genera los nombres de las columnas codificadas.\n",
    "            _dataframe = pd.DataFrame(\n",
    "                encoded,\n",
    "                columns= cols\n",
    "            )\n",
    "            # Añade el DataFrame codificado a la lista.\n",
    "            encoded_vars.append(_dataframe)\n",
    "        # Devuelve la concatenación de todos los DataFrames codificados.\n",
    "        return pd.concat(encoded_vars,axis=1)\n",
    "\n",
    "    def run(self) -> pd.DataFrame:\n",
    "        # Log de inicio del pipeline.\n",
    "        logger.info(f\"Inicializando pipeline {self.pipeline_name}\")\n",
    "\n",
    "        # Codifica las variables categóricas.\n",
    "        categorical = self.encode_categoricals()\n",
    "        # Procesa las variables numéricas.\n",
    "        numerics = self.impute_scale()\n",
    "\n",
    "        # Une las variables categóricas y numéricas.\n",
    "        modeling_dataset = pd.concat([categorical, numerics], axis=1)\n",
    "\n",
    "        pipe = Pipeline(\n",
    "            steps=[\n",
    "                # Elimina variables con baja varianza.\n",
    "                (\"feature_selection\", VarianceThreshold()),\n",
    "                # Escala las variables usando RobustScaler.\n",
    "                (\"scaling_robust\", RobustScaler())\n",
    "            ]\n",
    "        )\n",
    "        # Aplica el pipeline y guarda el resultado en feature_table.\n",
    "        self.feature_table =  pd.DataFrame(\n",
    "            pipe.fit_transform(modeling_dataset),\n",
    "            columns=modeling_dataset.columns\n",
    "        )\n",
    "\n",
    "        # Añade una columna de IDs únicos.\n",
    "        self.feature_table[\"booking_id\"] = [str(uuid.uuid4()) for _ in range(self.feature_table.shape[0])]\n",
    "        # Añade una columna de timestamp.\n",
    "        self.feature_table[\"event_timestamp\"] = [datetime.now() for _ in range(self.feature_table.shape[0])]\n",
    "        \n",
    "        import time\n",
    "        # Espera 1 segundo.\n",
    "        time.sleep(1)\n",
    "        # Añade una columna de timestamp de creación.\n",
    "        self.feature_table[\"created\"] = [datetime.now() for _ in range(self.feature_table.shape[0])]\n",
    "\n",
    "        # Devuelve la tabla final de características.\n",
    "        return self.feature_table\n",
    "\n",
    "    def write_feature_table(self, filepath: str) -> None:\n",
    "        # Log de escritura de la tabla.\n",
    "        logger.info(f\"Escribiendo feature table en {filepath}\")\n",
    "        if not self.feature_table.empty: # -> True o False\n",
    "            # Guarda la tabla en formato parquet.\n",
    "            self.feature_table.to_parquet(f\"{filepath}.parquet\", index=False)\n",
    "            # Guarda la tabla en formato csv.\n",
    "            self.feature_table.to_csv(f\"{filepath}.csv\", index=False)\n",
    "        else:\n",
    "            # Lanza excepción si la tabla no existe.\n",
    "            raise Exception(\"La feature table no ha sido creada. Ejecutar el comando .run()\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efdf455e-f1d0-42fa-953f-87fcebf45fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Hotel Booking -> https://www.kaggle.com/datasets/jessemostipak/hotel-booking-demand/data\n",
    "raw_data = pd.read_csv(\"../data/raw/hotel_bookings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7677f65",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5afc82e-441c-41f3-9b30-eab481712055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide el DataFrame en conjuntos de entrenamiento y prueba usando scikit-learn.\n",
    "train_raw_data, test_raw_data = train_test_split(\n",
    "    raw_data, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0fc452f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reserved_room_type\n",
       "A    68710\n",
       "D    15375\n",
       "E     5243\n",
       "F     2314\n",
       "G     1695\n",
       "B      914\n",
       "C      762\n",
       "H      483\n",
       "P       11\n",
       "L        5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw_data[\"reserved_room_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59cc910",
   "metadata": {},
   "source": [
    "## OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcccbf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hotel\n",
       "City Hotel      63486\n",
       "Resort Hotel    32026\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw_data[\"hotel\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7135fac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['City Hotel', 'Resort Hotel'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Crea una instancia del codificador OneHotEncoder.\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Ajusta el codificador a la columna 'hotel' del conjunto de entrenamiento y transforma los datos en una matriz codificada (one-hot).\n",
    "encoded = encoder.fit_transform(train_raw_data[[\"hotel\"]])\n",
    "\n",
    "# Muestra las categorías únicas encontradas en la columna 'hotel' durante el ajuste.\n",
    "encoder.categories_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d0ea691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['City Hotel', 'Resort Hotel'], dtype=object)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processor = FeatureEngineeringProcessor(\n",
    "    raw_data=train_raw_data,\n",
    "    pipeline_name=\"train_pipeline\"\n",
    ")\n",
    "# Ejecuta el procesamiento de características.\n",
    "train_processor.run()\n",
    "\n",
    "# Guarda la tabla de características en disco.\n",
    "train_processor.write_feature_table(\"../data/processed/bookings_feature_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac001d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processor = FeatureEngineeringProcessor(\n",
    "    raw_data=test_raw_data,\n",
    "    pipeline_name=\"test_pipeline\"\n",
    ")\n",
    "# Ejecuta el procesamiento de características.\n",
    "test_processor.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
